{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab5 - FS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Набор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_dataset(path: str):\n",
    "    if path.endswith('tsv'):\n",
    "        return pd.read_csv(path, sep='\\t')\n",
    "    else:\n",
    "        return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление пунктуации и чисел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text: str):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведение слов к начальной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import MorphVocab, Doc, Segmenter, NewsEmbedding, NewsMorphTagger\n",
    "\n",
    "morph_vocab = MorphVocab()\n",
    "segmenter = Segmenter()\n",
    "emd = NewsEmbedding()\n",
    "morph_tager = NewsMorphTagger(emd)\n",
    "\n",
    "def lemmatize_text(text: str):\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tager)\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    lemmas = [token.lemma for token in doc.tokens]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "def split_dataset(dataset, target_feature):\n",
    "    y = pd.DataFrame(label_encoder.fit_transform(dataset[target_feature]), columns=[target_feature])\n",
    "    X = dataset.drop(columns=[target_feature])\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(path, target_feature, text_feature):\n",
    "    df = load_dataset(path)\n",
    "    df[text_feature] = df[text_feature].apply(clean_text)\n",
    "    df[text_feature] = df[text_feature].apply(lemmatize_text)\n",
    "    df.to_csv('data/preprocessed.csv', index=False)\n",
    "    return split_dataset(df, target_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_dataset('data/castle-or-lock.tsv', 'class', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = pd.read_csv('data/preprocessed.csv')\n",
    "X_train, X_test, y_train, y_test = split_dataset(preprocessed, 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>засов дверной задвижка шпингалет больший задви...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>замок с магнитный ключ или замок с магнитный к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>крепость пфальцграфенштайна он burg pfalzgrafe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>замок гапсалить он bischofsburg hapsal ныне им...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>электромеханический замок разновидность электр...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "50  засов дверной задвижка шпингалет больший задви...\n",
       "72  замок с магнитный ключ или замок с магнитный к...\n",
       "39  крепость пфальцграфенштайна он burg pfalzgrafe...\n",
       "25  замок гапсалить он bischofsburg hapsal ныне им...\n",
       "61  электромеханический замок разновидность электр..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритмы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Встроенный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class CustomEmbedded:\n",
    "    def __init__(self, n_top=30):\n",
    "        self.n_top=n_top\n",
    "    \n",
    "    def select(self, X, y):\n",
    "        y = y.ravel()\n",
    "        model = LinearSVC()\n",
    "        model.fit(X, y)\n",
    "        feature_weights = np.abs(model.coef_[0])\n",
    "\n",
    "        return np.argsort(feature_weights)[-self.n_top:][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрующий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\chi^2=\\sum\\limits_{i=1}^n{\\frac{(n_{эмпир} - n_{теор})^2}{n_{теор}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CustomFilter:\n",
    "    def __init__(self, n_top=30):\n",
    "        self.n_top=n_top\n",
    "\n",
    "    # m[i, j]: i - признак присутствует, j - класс равен cls\n",
    "    def _build_empirical_matrix(self, feature, cls):\n",
    "        m = np.zeros((2, 2))\n",
    "        m[0][0] = np.sum(np.logical_and(feature == 0, self.y != cls))\n",
    "        m[0][1] = np.sum(np.logical_and(feature == 0, self.y == cls))\n",
    "        m[1][0] = np.sum(np.logical_and(feature > 0, self.y != cls))\n",
    "        m[1][1] = np.sum(np.logical_and(feature > 0, self.y == cls))\n",
    "        return m\n",
    "    \n",
    "    def _build_expected_matrix(self, empirical_matrix):\n",
    "        total_with_feature = empirical_matrix[1][1] + empirical_matrix[1][0]\n",
    "        total_without_feature = empirical_matrix[0][0] + empirical_matrix[0][1]\n",
    "        total_of_cls = empirical_matrix[0][1] + empirical_matrix[1][1]\n",
    "        total_of_not_cls = empirical_matrix[0][0] + empirical_matrix[1][0]\n",
    "        total = total_with_feature + total_without_feature\n",
    "\n",
    "        m = np.zeros((2, 2))\n",
    "        m[0][0] = (total_without_feature * total_of_not_cls) / total\n",
    "        m[0][1] = (total_without_feature * total_of_cls) / total\n",
    "        m[1][0] = (total_with_feature * total_of_not_cls) / total\n",
    "        m[1][1] = (total_with_feature * total_of_cls) / total\n",
    "        \n",
    "        return m\n",
    "    \n",
    "    def _compute_chi2(self, empirical_matrix, expected_matrix):\n",
    "        chi2 = 0\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                if (expected_matrix[i, j]) > 0:\n",
    "                    chi2 += ((empirical_matrix[i, j] - expected_matrix[i, j]) ** 2) / expected_matrix[i, j]\n",
    "        return chi2\n",
    "\n",
    "    def select(self, X, y):\n",
    "        self.y = y\n",
    "        n_samples, n_features = X.shape\n",
    "        chi2_scores = []\n",
    "\n",
    "        for i in range(n_features):\n",
    "            feature = X[:, i].flatten()\n",
    "            chi2 = 0\n",
    "\n",
    "            for cls in np.unique(y):\n",
    "                empirical_matrix = self._build_empirical_matrix(feature, cls)\n",
    "                expected_matrix = self._build_expected_matrix(empirical_matrix)\n",
    "                print(empirical_matrix == expected_matrix)\n",
    "                chi2 += self._compute_chi2(empirical_matrix, expected_matrix)\n",
    "            \n",
    "            chi2_scores.append(chi2)\n",
    "        \n",
    "        return np.argsort(chi2_scores)[-self.n_top:][::-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обертка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "\n",
    "class CustomWrapper:\n",
    "    def __init__(self, n_top=30, model=LogisticRegression(), metric=accuracy_score):\n",
    "        self.n_top=n_top\n",
    "        self.model=model\n",
    "        self.metric=metric\n",
    "    \n",
    "    def select(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        y = y.ravel()\n",
    "        features = list(range(n_features))\n",
    "        current_features = []\n",
    "        for _ in tqdm(range(self.n_top)):\n",
    "            best_score = -np.inf\n",
    "            best_feature = None\n",
    "\n",
    "            for feature in features:\n",
    "                if (feature in current_features):\n",
    "                    continue\n",
    "\n",
    "                temp_features = current_features + [feature]\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X[:, temp_features], y, test_size=0.3, random_state=7)\n",
    "\n",
    "                self.model.fit(X_train, y_train)\n",
    "                y_pred = self.model.predict(X_test)\n",
    "\n",
    "                score = self.metric(y_pred, y_test)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_feature = feature\n",
    "            current_features.append(best_feature)\n",
    "        self.best_features = current_features\n",
    "\n",
    "        return self.best_features\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ladyp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "russian_stopwords = list(stopwords.words('russian'))\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=5000, stop_words=russian_stopwords)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train['text'])\n",
    "X_test_vectorized = vectorizer.transform(X_test['text'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "X_train_vectorized = pd.DataFrame(X_train_vectorized.toarray(), columns=feature_names)\n",
    "X_test_vectorized = pd.DataFrame(X_test_vectorized.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names_from_indeces(indeces):\n",
    "    return feature_names[indeces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 2],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фильтрующий метод (χ²): ['ii', 'башня', 'безопасность', 'бруэма', 'век', 'война', 'время', 'год', 'город', 'дверь', 'де', 'зал', 'защелка', 'использоваться', 'клиффорд', 'ключ', 'колесо', 'конструкция', 'король', 'крепость', 'механизм', 'мочь', 'обычно', 'построить', 'резиденция', 'стена', 'устройство', 'цилиндр', 'штифт', 'электронный']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "chi2_selector = SelectKBest(chi2, k=30)  # Выбираем 30 признаков\n",
    "X_chi2 = chi2_selector.fit_transform(X_train_vectorized.values, y_train.values)\n",
    "\n",
    "selected_words_chi2 = [vectorizer.get_feature_names_out()[i] for i in chi2_selector.get_support(indices=True)]\n",
    "print(\"Фильтрующий метод (χ²):\", selected_words_chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparsity: 0.946\n",
      "Min sparsity: 0.000\n",
      "Max sparsity: 0.985\n",
      "Class 0: 32 samples (47.8%)\n",
      "Class 1: 35 samples (52.2%)\n",
      "\n",
      "Feature 0, Class 0\n",
      "Empirical matrix:\n",
      "[[2205. 2016.]\n",
      " [ 140.  128.]]\n",
      "Expected matrix:\n",
      "[[2205. 2016.]\n",
      " [ 140.  128.]]\n",
      "\n",
      "Feature 0, Class 1\n",
      "Empirical matrix:\n",
      "[[2016. 2205.]\n",
      " [ 128.  140.]]\n",
      "Expected matrix:\n",
      "[[2016. 2205.]\n",
      " [ 128.  140.]]\n",
      "\n",
      "Feature 1, Class 0\n",
      "Empirical matrix:\n",
      "[[2275. 2080.]\n",
      " [  70.   64.]]\n",
      "Expected matrix:\n",
      "[[2275. 2080.]\n",
      " [  70.   64.]]\n",
      "\n",
      "Feature 1, Class 1\n",
      "Empirical matrix:\n",
      "[[2080. 2275.]\n",
      " [  64.   70.]]\n",
      "Expected matrix:\n",
      "[[2080. 2275.]\n",
      " [  64.   70.]]\n",
      "\n",
      "Feature 2, Class 0\n",
      "Empirical matrix:\n",
      "[[2310. 2112.]\n",
      " [  35.   32.]]\n",
      "Expected matrix:\n",
      "[[2310. 2112.]\n",
      " [  35.   32.]]\n",
      "\n",
      "Feature 2, Class 1\n",
      "Empirical matrix:\n",
      "[[2112. 2310.]\n",
      " [  32.   35.]]\n",
      "Expected matrix:\n",
      "[[2112. 2310.]\n",
      " [  32.   35.]]\n"
     ]
    }
   ],
   "source": [
    "f = CustomFilter()\n",
    "top_indeces = f.select(X_train_vectorized.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abloy', 'ящик', 'яхта', 'ясный', 'ярус', 'яркоголубой', 'ярко',\n",
       "       'янош', 'an', 'ancestors', 'and', 'ansi', 'assa', 'at', 'august',\n",
       "       'berg', 'best', 'bhma', 'ble', 'bluetooth', 'bramah', 'breeden',\n",
       "       'briggs', 'brougham', 'эрик', 'эркер', 'эстенс', 'эстония',\n",
       "       'эстонский', 'этаж'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_from_indeces(top_indeces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
